<!DOCTYPE HTML>

<style>
  #full {
    display: none;
  }
  </style>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Song Wang</title>
  
  <meta name="author" content="Song Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>


<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Song Wang</name>
              </p>
              <p> 
                I am a Ph.D. student in the College of Computer Science and Technology at Zhejiang University, advised by Prof. <a href="https://person.zju.edu.cn/jkzhu">Jianke Zhu</a>. 
                Prior to that, I obtained my B.Eng. at Zhejiang University, supervised by Prof. <a href="https://person.zju.edu.cn/0014142">Zhiwei Xu</a> and Prof. <a href="https://person.zju.edu.cn/0012062">Hangfang Zhao</a>.
                And now, I am also a visiting Ph.D. student @ <a href="https://sites.google.com/view/xml-nus">xML-Lab</a>, National University of Singapore, co-advised by Prof. <a href="https://sites.google.com/site/sitexinchaowang">Xinchao Wang</a>.
              </p>
              <p>
              I have broad research interests in computer vision and machine learning. My current research focuses on:
              <li style="margin: 5px;" >
                <b>Post-training for multi-modal large language models (MLLM)</b> along with efficient reasoning.
              </li>
                <li style="margin: 5px;" >
                  <b>Pre-training and parameter-efficient fine-tuning (PEFT)</b>  for multi-modal foundation models.
                </li>
                <li style="margin: 5px;" >
                  <b>Vision-centric autonomous driving</b> including occupancy network and semantic map construction.
                </li>
                <!-- <li style="margin: 5px;" >
                  <b>LiDAR perception</b> including semantic segmentation and map construction.
                </li> -->
              </p>
              <p>
                <b>Various forms of academic collaboration and discussion are welcome. Feel free to reach out!</b>
              </p>
              <p style="text-align:center">
                <a href="mailto:songw@zju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Jj0jbL8AAAAJ"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/songw-zju"> Github </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:50%;max-width:50%" alt="profile photo" src="images/wangsong.jpg">
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
        </tr>
      </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p><heading>Publications</heading></p>
              <p>
                * indicates equal contribution
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PixelThink.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>PixelThink: Towards Efficient Chain-of-Pixel Reasoning</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href="https://fangggf.github.io"> Gongfan Fang</a>,
              <a href="https://ldkong.com"> Lingdong Kong</a>,
              <a href="https://lxtgh.github.io"> Xiangtai Li</a>,
              <a href="https://scholar.google.com/citations?user=LctFPtgAAAAJ"> Jianyun Xu</a>,
              <a href="https://scholar.google.com/citations?user=G6IztksAAAAJ"> Sheng Yang</a>, 
              <a href="https://www.linkedin.cn/incareer/in/qiang-li-37196013"> Qiang Li</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://sites.google.com/site/sitexinchaowang"> Xinchao Wang</a>
              <br>
              <em><strong>arXiv</strong></em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2505.23727">[arXiv]</a>
              <a href="https://github.com/songw-zju/PixelThink">[Code]</a>
              <a href="https://pixelthink.github.io/">[Project Page]</a>
              <br>
            </td>
          </tr>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ReasonMap.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps</papertitle>
              <br>
              <a href="https://fscdc.github.io"> Sicheng Feng*</a>,
              <strong>Song Wang*</strong>, 
              <a href="https://scholar.google.com/citations?user=pQgChLEAAAAJ"> Shuyi Ouyang</a>,
              <a href="https://ldkong.com"> Lingdong Kong</a>,
              <a href="https://skyesong38.github.io"> Zikai Song</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://huanwang.tech"> Huan Wang</a>,
              <a href="https://sites.google.com/site/sitexinchaowang"> Xinchao Wang</a>
              <br>
              <em><strong>arXiv</strong></em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2505.18675">[arXiv]</a>
              <a href="https://github.com/fscdc/ReasonMap">[Code]</a>
              <a href="https://fscdc.github.io/Reason-Map">[Project Page]</a>
              <a href="https://mp.weixin.qq.com/s/sPJLQtHgl5DZghWLWa_H3Q">[中文解读]</a>
              <br>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/SAM4D.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>SAM4D: Segment Anything in Camera and LiDAR Streams</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=LctFPtgAAAAJ"> Jianyun Xu*</a>,
              <strong>Song Wang*</strong>, 
              <a href="https://github.com/nizqleo"> Ziqian Ni*</a>,
              <a href="https://scholar.google.com/citations?user=y1_8HucAAAAJ"> Chunyong Hu</a>, 
              <a href="https://scholar.google.com/citations?user=G6IztksAAAAJ"> Sheng Yang</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://www.linkedin.cn/incareer/in/qiang-li-37196013"> Qiang Li</a>
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2506.21547">[arXiv]</a>
              <a href="https://github.com/CN-ADLab/SAM4D">[Code]</a>
              <a href="https://sam4d-project.github.io/">[Project Page]</a>
              <br>
            </td>
          </tr>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PointLoRA.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>,
              <a href="https://ldkong.com"> Lingdong Kong</a>,
              <a href="https://scholar.google.com/citations?user=LctFPtgAAAAJ"> Jianyun Xu</a>,
              <a href="https://scholar.google.com/citations?user=y1_8HucAAAAJ"> Chunyong Hu</a>, 
              <a href="https://fangggf.github.io"> Gongfan Fang</a>,
              <a href="https://cslwt.github.io"> Wentong Li</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://sites.google.com/site/sitexinchaowang"> Xinchao Wang</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2504.16023">[arXiv]</a>
              <a href="https://github.com/songw-zju/PointLoRA">[Code]</a>
              <br>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Inst3D-LMM.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning</papertitle>
              <br>
              <a href="https://hanxunyu.github.io"> Hanxun Yu*</a>,
              <a href="https://cslwt.github.io"> Wentong Li*</a>, 
              <strong>Song Wang</strong>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR Highlight</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2503.00513">[arXiv]</a>
              <a href="https://github.com/hanxunyu/Inst3D-LMM">[Code]</a>
              <br>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/UIGenMap.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Uncertainty-Instructed Structure Injection for Generalizable HD Map Construction</papertitle>
              <br>
              <a href="https://github.com/xiaolul2"> Xiaolu Liu*</a>,
              <a href=""> Ruizi Yang*</a>,
              <strong>Song Wang</strong>, 
              <a href="https://cslwt.github.io"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2503.23109">[arXiv]</a>
              <a href="https://github.com/xiaolul2/UIGenMap">[Code]</a>
              <br>
            </td>
          </tr>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ReliOcc.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Reliable and Calibrated Semantic Occupancy Prediction by Hybrid Uncertainty Learning</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href="https://zhongdao.github.io/"> Zhongdao Wang</a>, 
              <a href=""> Jiawei Yu</a>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations&user=4oxEdy4AAAAJ"> Bailan Feng</a>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2409.18026">[arXiv]</a>
              <a href="">[Code]</a>
              <br>
            </td>
          </tr>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PianoMotion.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance</papertitle>
              <br>
              <a href="https://agnjason.github.io"> Qijun Gan</a>,
              <strong>Song Wang</strong>, 
              <a href=""> Shengtao Wu</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>International Conference on Learning Representations (<strong>ICLR Spotlight</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2406.09326">[arXiv]</a>
              <a href="https://github.com/agnJason/PianoMotion10M">[Code]</a>
              <br>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/TokenPacker.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>TokenPacker: Efficient Visual Projector for Multimodal LLM</papertitle>
              <br>
              <a href="https://cslwt.github.io/"> Wentong Li*</a>, 
              <a href="https://yuqianyuan.github.io/"> Yuqian Yuan*</a>,
              <a href=""> Jian Liu</a>,
              <a href=""> Dongqi Tang</a>,
              <strong>Song Wang</strong>, 
              <a href="https://sites.google.com/site/firmamentqj"> Jie Qin</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"> Lei Zhang</a>
              <br>
               <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2407.02392">[arXiv]</a>
              <a href="https://github.com/CircleRadon/TokenPacker">[Code]</a>
              <br>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/OccFiner.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Offboard Occupancy Refinement with Hybrid Propagation for Autonomous Driving</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=0EI9msQAAAAJ"> Hao Shi*</a>, 
              <strong>Song Wang*</strong>, 
              <a href="https://jamycheung.github.io/"> Jiaming Zhang</a>, 
              <a href=""> Xiaoting Yin</a>,
              <a href="https://zhongdao.github.io/"> Zhongdao Wang</a>,
              <a href=""> Zhijian Zhao</a>,
              <a href="https://guangmingw.github.io/"> Guangming Wang</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://yangkailun.com/"> Kailun Yang</a>,
              <a href="https://scholar.google.com/citations?user=B6xWNvgAAAAJ"> Kaiwei Wang</a>
              <br>
              <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2403.08504">[arXiv]</a>
              <a href="https://github.com/MasterHow/OccFiner">[Code]</a>
              <br>
              <!-- <p> In addressing the challenges of inferior performance and data closure in vision-based SSC, we introduce OccFiner, the first offboard SSC setup to solve the unreliability of the onboard model.</p> -->
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Scribble2Scene.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Label-efficient Semantic Scene Completion With Scribble Annotations</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href=""> Jiawei Yu</a>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=0EI9msQAAAAJ"> Hao Shi</a>, 
              <a href="https://yangkailun.com/"> Kailun Yang</a>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2024
              <br>
              <a href="http://arxiv.org/abs/2405.15170">[arXiv]</a>
              <a href="https://github.com/songw-zju/Scribble2Scene">[Code]</a>
              <br>
              <!-- <p> In this work, we have presented a scribble-based label-efficient benchmark ScribbleSC for semantic scene completion in autonomous driving. To enhance the performance in this setting, an effective scribble-supervised approach Scribble2Scene has been developed.</p> -->
            </td>
          </tr>

        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/HASSC.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href=""> Jiawei Yu</a>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ&hl=en"> Wenyu Liu</a>, 
              <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2404.11958">[arXiv]</a>
              <a href="https://github.com/songw-zju/HASSC">[Code]</a>
              <br>
              <!-- <p>  In this paper, we adhere to the principle of not all voxels are equal and propose hardness-aware semantic scene completion (HASSC). </p> -->
            </td>
          </tr>

        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="images/MGMap.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction</papertitle>
                <br>
                <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>, 
                <strong>Song Wang</strong>, 
                <a href="https://cslwt.github.io/"> Wentong Li</a>, 
                <a href=""> Ruizi Yang</a>,
                <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
                <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2404.00876">[arXiv]</a>
                <a href="https://github.com/xiaolul2/MGMap">[Code]</a>
                <br>
                <!-- <p> In this paper, we propose MGMap, an effective approach to online HD map vectorization with the guidance of learned masks.</p> -->
              </td>
            </tr>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ACSegFormer.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Domain Adaptation Transformer for Unsupervised Driving-Scene Segmentation in Adverse Conditions</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ&hl=en"> Wenyu Liu</a>, 
              <strong>Song Wang</strong>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://scholar.google.com/citations?user=M0Ei1zkAAAAJ"> Xuansong Xie</a>,
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"> Lei Zhang</a>
              <br>
              <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2024
              <br>
              <a href="https://ieeexplore.ieee.org/document/10696911">[Paper]</a>
              <a href="">[Code]</a>
              <br>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/DTCLMapper.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>DTCLMapper: Dual Temporal Consistent Learning for Vectorized HD Map Construction</papertitle>
              <br>
              <a href=""> Siyu Li</a>, 
              <a href="https://scholar.google.com/citations?user=rFiGjVEAAAAJ"> Jiacheng Lin</a>, 
              <a href="https://scholar.google.com/citations?user=0EI9msQAAAAJ"> Hao Shi</a>,
              <a href="https://jamycheung.github.io/"> Jiaming Zhang</a>, 
              <strong>Song Wang</strong>, 
              <a href=""> You Yao</a>,
              <a href="https://scholar.google.com/citations?user=LRfEEuEAAAAJ"> Zhiyong Li</a>,
              <a href="https://yangkailun.com/"> Kailun Yang</a>
              <br>
              <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2405.05518">[arXiv]</a>
              <a href="https://github.com/lynn-yu/DTCLMapper">[Code]</a>
              <br>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/APro.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Label-efficient Segmentation via Affinity Propagation</papertitle>
              <br>
              <a href="https://cslwt.github.io/"> Wentong Li*</a>, 
              <a href="https://yuqianyuan.github.io/"> Yuqian Yuan*</a>,
              <strong>Song Wang</strong>, 
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ&hl=en"> Wenyu Liu</a>, 
              <a href=""> Dongqi Tang</a>,
              <a href=""> Jian Liu</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"> Lei Zhang</a>
              <br>
              <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2310.10533">[arXiv]</a>
              <a href="https://github.com/CircleRadon/APro">[Code]</a>
              <a href="https://liwentomng.github.io/apro">[Project Page]</a>
              <br>
              <!-- <p> We propose a method named APro, designed to generate precise soft pseudo labels online for unlabeled regions within segmentation networks.</p> -->
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Point2Mask.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport</papertitle>
              <br>
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://yuqianyuan.github.io/"> Yuqian Yuan</a>,
              <strong>Song Wang</strong>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://scholar.google.com/citations?user=yyz7kMsAAAAJ"> Jianshu Li</a>,
              <a href=""> Jian Liu</a>, 
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"> Lei Zhang</a>
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2308.01779">[arXiv]</a>
              <a href="https://github.com/LiWentomng/Point2Mask">[Code]</a>
              <br>
              <!-- <p> In this paper, we present an effective method, namely Point2Mask, to achieve highquality panoptic prediction using only a single random point annotation per target for training.</p> -->
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/LiDAR2Map.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using Online Camera Distillation</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ"> Wenyu Liu</a>, 
              <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2304.11379">[arXiv]</a>
              <a href="https://github.com/songw-zju/LiDAR2Map">[Code]</a>
              <br>
              <!-- <p> In this work, an efficient semantic map construction framework named LiDAR2Map, is presented with an effective BEV feature pyramid decoder and an online Camera-to-LiDAR distillation scheme.</p> -->
            </td>
          </tr>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Meta-RangeSeg.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Meta-RangeSeg: LiDAR Sequence Semantic Segmentation Using Multiple Feature Aggregation</papertitle>
              <br>
              <strong>Song Wang</strong>,   
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>, 
              <a href="https://scholar.google.com/citations?user=5UVo7HYAAAAJ&hl=en"> Ruixiang Zhang</a>
              <br>
              <em>IEEE Robotics and Automation Letters (<strong>RA-L with IROS</strong>, IF: 5.2)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2202.13377">[arXiv]</a> 
              <a href="https://github.com/songw-zju/Meta-RangeSeg">[Code]</a> 
              <br>
              <!-- <p> We propose a novel approach to LiDAR semantic segmentation, which introduces a range residual image representation to capture the spatial-temporal information. </p> -->
            </td>
          </tr>
        </tbody></table>

        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> Chen Tianzhou Scholarship, Zhejiang University</li>
                <li style="margin: 5px;"> China's Optics Valley Scholarship, Donghu New Technology Development Zone</li>
                <li style="margin: 5px;"> Graduate with Merit A Performance, Zhejiang University</li>
                <li style="margin: 5px;"> Third Prize in China Graduate AI Innovation Competition, Ministry of Education</li>
                <li style="margin: 5px;"> Award of Honor for Graduate, Zhejiang University</li>
                <li style="margin: 5px;"> Outstanding Academic Scholarship, Zhejiang University</li>
                <li style="margin: 5px;"> Outstanding Undergraduate Award, Zhejiang University</li>
                <li style="margin: 5px;"> Zhejiang Provincial Government Scholarship, Zhejiang Province </li>
                <li style="margin: 5px;"> Zhongtian Technology First-Class Scholarship, ZTT Group </li>
                <li style="margin: 5px;"> Zhejiang University Scholarship - Second Prize, Zhejiang University </li>
                <li style="margin: 5px;"> First Prize in Advanced Mathematics Competition, Zhejiang Province </li>
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> Conference Reviewer: ICML 2025, IJCAI 2025, CVPR 2025, ICLR 2025, IROS 2025, NeurIPS D&B Track 2024-2025, NeurIPS 2024, ECCV 2024, ACM MM 2023-2024, ICRA 2024-2025, SynData4CV@CVPR 2024</li>
              <li style="margin: 5px;"> Journal Reviewer: IEEE T-IP, IEEE T-ITS, IEEE T-CSVT, IEEE RA-L, IEEE T-IV</li>
            </p>
          </td>
        </tr>
      </tbody></table>
       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
 
<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
<!-- 	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=yp3s8rdiQW_pbzmBOzWDx2Fv6afIlEpV-k1EZiYIkEY"></script> -->
	  </div>        
	  <br>
	    &copy; Song Wang | Last updated: June 28, 2025
</center></p>
</body>

</html>
