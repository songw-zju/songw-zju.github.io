<!DOCTYPE HTML>

<style>
  #full {
    display: none;
  }
  </style>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Song Wang</title>
  
  <meta name="author" content="Song Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>


<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Song Wang</name>
              </p>
              <p> 
                I am a Ph.D. student in the College of Computer Science and Technology at Zhejiang University, advised by Prof. <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu </a>. 
                Prior to that, I obtained my B.Eng. at Zhejiang University, supervised by Prof. <a href="https://person.zju.edu.cn/0014142"> Zhiwei Xu </a> and Prof. <a href="https://person.zju.edu.cn/0012062"> Hangfang Zhao </a>.
              </p>
              <p>
              I am interested in computer vision and machine learning. My current research focuses on:
              <li style="margin: 5px;" >
                <b>Vision-language models</b> for visual tasks and applications.
              </li>
                <li style="margin: 5px;" >
                  <b>Vision-centric occupancy network</b> a.k.a semantic scene completion.
                </li>
                <li style="margin: 5px;" >
                  <b>Label-efficient learning</b> for 2D and 3D dense prediction.
                </li>
                <!-- <li style="margin: 5px;" >
                  <b>LiDAR perception</b> including semantic segmentation and map construction.
                </li> -->
              </p>
              <p>
                <b>Various forms of academic collaboration and discussion are welcome. Feel free to reach out!</b>
              </p>
              <p style="text-align:center">
                <a href="mailto:songw@zju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Jj0jbL8AAAAJ"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/songw-zju"> Github </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:50%;max-width:50%" alt="profile photo" src="images/wangsong.jpg">
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
        </tr>
      </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p><heading>Publications</heading></p>
              <p>
                * indicates equal contribution
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/OccFiner.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>OccFiner: Offboard Occupancy Refinement with Hybrid Propagation</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=0EI9msQAAAAJ"> Hao Shi*</a>, 
              <strong>Song Wang*</strong>, 
              <a href="https://jamycheung.github.io/"> Jiaming Zhang</a>, 
              <a href=""> Xiaoting Yin</a>,
              <a href="https://zhongdao.github.io/"> Zhongdao Wang</a>,
              <a href=""> Zhijian Zhao</a>,
              <a href="https://guangmingw.github.io/"> Guangming Wang</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://yangkailun.com/"> Kailun Yang</a>,
              <a href="https://scholar.google.com/citations?user=B6xWNvgAAAAJ"> Kaiwei Wang</a>
              <br>
              <em><strong>arXiv</strong></em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2403.08504">[arXiv]</a>
              <a href="">[Code]</a>
              <br>
              <p> In addressing the challenges of inferior performance and data closure in vision-based SSC, we introduce OccFiner, the first offboard SSC setup to solve the unreliability of the onboard model.</p>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Scribble2Scene.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Label-efficient Semantic Scene Completion With Scribble Annotations</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href=""> Jiawei Yu</a>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=0EI9msQAAAAJ"> Hao Shi</a>, 
              <a href="https://yangkailun.com/"> Kailun Yang</a>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2024
              <br>
              <a href="">[arXiv]</a>
              <a href="https://github.com/songw-zju/Scribble2Scene">[Code]</a>
              <br>
              <p> In this work, we have presented a scribble-based label-efficient benchmark ScribbleSC for semantic scene completion in autonomous driving. To enhance the performance in this setting, an effective scribble-supervised approach Scribble2Scene has been developed.</p>
            </td>
          </tr>

        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/HASSC.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href=""> Jiawei Yu</a>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ&hl=en"> Wenyu Liu</a>, 
              <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>, 
              <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2404.11958">[arXiv]</a>
              <a href="https://github.com/songw-zju/HASSC">[Code]</a>
              <br>
              <p>  In this paper, we adhere to the principle of not all voxels are equal and propose hardness-aware semantic scene completion (HASSC). </p>
            </td>
          </tr>

        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="images/MGMap.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction</papertitle>
                <br>
                <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>, 
                <strong>Song Wang</strong>, 
                <a href="https://cslwt.github.io/"> Wentong Li</a>, 
                <a href=""> Ruizi Yang</a>,
                <a href="https://scholar.google.com/citations?user=4YOIYGwAAAAJ"> Junbo Chen</a>,
                <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2404.00876">[arXiv]</a>
                <a href="https://github.com/xiaolul2/MGMap">[Code]</a>
                <br>
                <p> In this paper, we propose MGMap, an effective approach to online HD map vectorization with the guidance of learned masks.</p>
              </td>
            </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/APro.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Label-efficient Segmentation via Affinity Propagation</papertitle>
              <br>
              <a href="https://cslwt.github.io/"> Wentong Li*</a>, 
              <a href="https://yuqianyuan.github.io/"> Yuqian Yuan*</a>,
              <strong>Song Wang</strong>, 
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ&hl=en"> Wenyu Liu</a>, 
              <a href=""> Dongqi Tang</a>,
              <a href=""> Jian Liu</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"> Lei Zhang</a>
              <br>
              <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2310.10533">[arXiv]</a>
              <a href="https://github.com/CircleRadon/APro">[Code]</a>
              <a href="https://liwentomng.github.io/apro">[Project Page]</a>
              <br>
              <p> We propose a method named APro, designed to generate precise soft pseudo labels online for unlabeled regions within segmentation networks.</p>
            </td>
          </tr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/point2mask.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport</papertitle>
              <br>
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://yuqianyuan.github.io/"> Yuqian Yuan</a>,
              <strong>Song Wang</strong>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>,
              <a href="https://scholar.google.com/citations?user=yyz7kMsAAAAJ"> Jianshu Li</a>,
              <a href=""> Jian Liu</a>, 
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/"> Lei Zhang</a>
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2308.01779">[arXiv]</a>
              <a href="https://github.com/LiWentomng/Point2Mask">[Code]</a>
              <br>
              <p> In this paper, we present an effective method, namely Point2Mask, to achieve highquality panoptic prediction using only a single random point annotation per target for training.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/LiDAR2Map.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using Online Camera Distillation</papertitle>
              <br>
              <strong>Song Wang</strong>, 
              <a href="https://cslwt.github.io/"> Wentong Li</a>, 
              <a href="https://scholar.google.com/citations?user=JloV4T0AAAAJ"> Wenyu Liu</a>, 
              <a href="https://github.com/xiaolul2"> Xiaolu Liu</a>, 
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2304.11379">[arXiv]</a>
              <a href="https://github.com/songw-zju/LiDAR2Map">[Code]</a>
              <br>
              <p> In this work, an efficient semantic map construction framework named LiDAR2Map, is presented with an effective BEV feature pyramid decoder and an online Camera-to-LiDAR distillation scheme.</p>
            </td>
          </tr>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Meta-RangeSeg.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Meta-RangeSeg: LiDAR Sequence Semantic Segmentation Using Multiple Feature Aggregation</papertitle>
              <br>
              <strong>Song Wang</strong>,   
              <a href="https://person.zju.edu.cn/jkzhu"> Jianke Zhu</a>, 
              <a href="https://scholar.google.com/citations?user=5UVo7HYAAAAJ&hl=en"> Ruixiang Zhang</a>
              <br>
              <em>IEEE Robotics and Automation Letters (<strong>RA-L with IROS</strong>, IF: 5.2)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2202.13377">[arXiv]</a> 
              <a href="https://github.com/songw-zju/Meta-RangeSeg">[Code]</a> 
              <br>
              <p> We propose a novel approach to LiDAR semantic segmentation, which introduces a range residual image representation to capture the spatial-temporal information. </p>
            </td>
          </tr>
        </tbody></table>

        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> China's Optics Valley Scholarship, Donghu New Technology Development Zone</li>
                <li style="margin: 5px;"> Graduate with Merit A Performance, Zhejiang University</li>
                <li style="margin: 5px;"> Award of Honor for Graduate, Zhejiang University</li>
                <li style="margin: 5px;"> Outstanding Undergraduate Award, Zhejiang University</li>
                <li style="margin: 5px;"> Zhejiang Provincial Government Scholarship, Zhejiang Province </li>
                <li style="margin: 5px;"> Zhongtian Technology First-Class Scholarship, ZTT Group </li>
                <li style="margin: 5px;"> Zhejiang University Scholarship - Second Prize, Zhejiang University </li>
                <li style="margin: 5px;"> First Prize in Advanced Mathematics Competition, Zhejiang Province </li>
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> Conference Reviewer: NeurIPS 2024, ECCV 2024, SynData4CV@CVPR 2024, ACM MM 2023-2024, ICRA 2024</li>
              <li style="margin: 5px;"> Journal Reviewer: IEEE Robotics and Automation Letters, IEEE Transactions on Intelligent Vehicles</li>
            </p>
          </td>
        </tr>
      </tbody></table>

<!--         
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Internships</heading>
            <p>
              <li style="margin: 5px;"> June. 2021: Research Intern at Hikvision Research Institute
              </li> 
              <li style="margin: 5px;"> October. 2020: Engineering Intern at VIVO AI Lab
              </li>
            </p>
          </td>
        </tr>
      </tbody></table> -->
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
 
<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
<!-- 	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=yp3s8rdiQW_pbzmBOzWDx2Fv6afIlEpV-k1EZiYIkEY"></script> -->
	  </div>        
	  <br>
	    &copy; Song Wang | Last updated: May 24, 2024
</center></p>
</body>

</html>
